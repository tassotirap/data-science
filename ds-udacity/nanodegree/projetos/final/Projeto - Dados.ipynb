{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.4\n",
      "0.20.1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "%matplotlib inline\n",
    "print(pd.__version__) # version 0.23.4\n",
    "print(sk.__version__) # version 0.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleared = df[df['AEROPORTO DE ORIGEM (PAÍS)'] == 'BRASIL']\n",
    "df_cleared = df_cleared[df_cleared['AEROPORTO DE DESTINO (PAÍS)'] != 'BRASIL']\n",
    "df_cleared['PASSAGEIROS_TOTAL'] = (df_cleared['PASSAGEIROS PAGOS'] + df_cleared['PASSAGEIROS GRÁTIS'])\n",
    "df_cleared = df_cleared[~np.isnan(df_cleared['PASSAGEIROS_TOTAL'])]\n",
    "df_cleared = df_cleared[df_cleared['ASSENTOS'] > 90] # mínimo de 120 lugares (aviões comerciais)\n",
    "df_cleared = df_cleared[df_cleared['ANO'] <= 2017]\n",
    "df_cleared = df_cleared[df_cleared['AEROPORTO DE ORIGEM (NOME)'] != 'AEROPORTO NÃO ENCONTRADO']\n",
    "df_cleared = df_cleared[df_cleared['AEROPORTO DE DESTINO (NOME)'] != 'AEROPORTO NÃO ENCONTRADO']\n",
    "\n",
    "df_cleared = df_cleared.drop([\n",
    "            'EMPRESA (SIGLA)', \n",
    "            'EMPRESA (NOME)', \n",
    "            'EMPRESA (NACIONALIDADE)', \n",
    "            'AEROPORTO DE ORIGEM (SIGLA)', \n",
    "            'AEROPORTO DE ORIGEM (NOME)',\n",
    "            'AEROPORTO DE ORIGEM (UF)',\n",
    "            'AEROPORTO DE ORIGEM (PAÍS)',\n",
    "            'AEROPORTO DE ORIGEM (CONTINENTE)',\n",
    "            'AEROPORTO DE DESTINO (SIGLA)',\n",
    "            'AEROPORTO DE DESTINO (NOME)',\n",
    "            'AEROPORTO DE DESTINO (UF)',\n",
    "            'AEROPORTO DE DESTINO (REGIÃO)',\n",
    "            'AEROPORTO DE DESTINO (PAÍS)',\n",
    "            'NATUREZA',\n",
    "            'GRUPO DE VOO',\n",
    "            'ASK',\n",
    "            'RPK',\n",
    "            'ATK',\n",
    "            'RTK',\n",
    "            'COMBUSTÍVEL (LITROS) - APENAS EMPRESAS BRASILEIRAS',\n",
    "            'CARGA GRATIS KM',\n",
    "            'CORREIO KM',\n",
    "            'PAYLOAD',\n",
    "            'HORAS VOADAS',\n",
    "            'BAGAGEM (KG)',\n",
    "            'CORREIO (KG)',\n",
    "            'CARGA PAGA KM',\n",
    "            'PASSAGEIROS PAGOS', \n",
    "            'PASSAGEIROS GRÁTIS', \n",
    "            'CARGA PAGA (KG)', \n",
    "            'CARGA GRÁTIS (KG)', \n",
    "            'DISTÂNCIA VOADA (KM)',\n",
    "            'ASSENTOS',\n",
    "            'DECOLAGENS'\n",
    "            ], axis=1)\n",
    "\n",
    "df_cleared.columns = ['ANO', 'MES', 'ORIGEM', 'DESTINO', 'PASSAGEIROS']\n",
    "df_cleared = df_cleared.groupby(['ANO', 'MES', 'ORIGEM', 'DESTINO'], as_index=False).sum()\n",
    "\n",
    "for year in range(2000, 2018):\n",
    "    for month in range(1, 13):\n",
    "        for origin in ['SUL', 'SUDESTE', 'NORTE', 'NORDESTE', 'CENTRO-OESTE']:\n",
    "            for destiny in ['AMÉRICA CENTRAL', 'AMÉRICA DO NORTE', 'AMÉRICA DO SUL', 'EUROPA', 'ÁFRICA', 'ÁSIA']:\n",
    "                    if df_cleared[(df_cleared['ANO'] == year) & (df_cleared['MES'] == month) & (df_cleared['ORIGEM'] == origin) & (df_cleared['DESTINO'] == destiny)].empty:\n",
    "                        df_cleared = df_cleared.append({ 'ANO': year, 'MES': month, 'ORIGEM': origin, 'DESTINO': destiny, 'PASSAGEIROS': 0}, ignore_index=True)\n",
    "                        \n",
    "df_cleared.to_csv('data/data_inter.csv', index=False)\n",
    "df_cleared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleared = df[df['AEROPORTO DE ORIGEM (PAÍS)'] == 'BRASIL']\n",
    "df_cleared = df_cleared[df_cleared['AEROPORTO DE DESTINO (PAÍS)'] == 'BRASIL']\n",
    "df_cleared['PASSAGEIROS_TOTAL'] = (df_cleared['PASSAGEIROS PAGOS'] + df_cleared['PASSAGEIROS GRÁTIS'])\n",
    "df_cleared = df_cleared[~np.isnan(df_cleared['PASSAGEIROS_TOTAL'])]\n",
    "df_cleared = df_cleared[df_cleared['ASSENTOS'] > 90] # mínimo de 120 lugares (aviões comerciais)\n",
    "df_cleared = df_cleared[df_cleared['ANO'] <= 2017]\n",
    "df_cleared = df_cleared[df_cleared['AEROPORTO DE ORIGEM (NOME)'] != 'AEROPORTO NÃO ENCONTRADO']\n",
    "df_cleared = df_cleared[df_cleared['AEROPORTO DE DESTINO (NOME)'] != 'AEROPORTO NÃO ENCONTRADO']\n",
    "\n",
    "df_cleared = df_cleared.drop([\n",
    "            'EMPRESA (SIGLA)', \n",
    "            'EMPRESA (NOME)', \n",
    "            'EMPRESA (NACIONALIDADE)', \n",
    "            'AEROPORTO DE ORIGEM (SIGLA)', \n",
    "            'AEROPORTO DE ORIGEM (NOME)',\n",
    "            'AEROPORTO DE ORIGEM (UF)',\n",
    "            'AEROPORTO DE ORIGEM (PAÍS)',\n",
    "            'AEROPORTO DE ORIGEM (CONTINENTE)',\n",
    "            'AEROPORTO DE DESTINO (SIGLA)',\n",
    "            'AEROPORTO DE DESTINO (NOME)',\n",
    "            'AEROPORTO DE DESTINO (UF)',\n",
    "            'AEROPORTO DE DESTINO (PAÍS)',\n",
    "            'AEROPORTO DE DESTINO (CONTINENTE)',\n",
    "            'NATUREZA',\n",
    "            'GRUPO DE VOO',\n",
    "            'ASK',\n",
    "            'RPK',\n",
    "            'ATK',\n",
    "            'RTK',\n",
    "            'COMBUSTÍVEL (LITROS) - APENAS EMPRESAS BRASILEIRAS',\n",
    "            'CARGA GRATIS KM',\n",
    "            'CORREIO KM',\n",
    "            'PAYLOAD',\n",
    "            'HORAS VOADAS',\n",
    "            'BAGAGEM (KG)',\n",
    "            'CORREIO (KG)',\n",
    "            'CARGA PAGA KM',\n",
    "            'PASSAGEIROS PAGOS', \n",
    "            'PASSAGEIROS GRÁTIS', \n",
    "            'CARGA PAGA (KG)', \n",
    "            'CARGA GRÁTIS (KG)', \n",
    "            'DISTÂNCIA VOADA (KM)',\n",
    "            'ASSENTOS',\n",
    "            'DECOLAGENS'\n",
    "            ], axis=1)\n",
    "\n",
    "df_cleared.columns = ['ANO', 'MES', 'ORIGEM', 'DESTINO', 'PASSAGEIROS']\n",
    "df_cleared = df_cleared.groupby(['ANO', 'MES', 'ORIGEM', 'DESTINO'], as_index=False).sum()\n",
    "\n",
    "for year in range(2000, 2018):\n",
    "    for month in range(1, 13):\n",
    "        for origin in ['SUL', 'SUDESTE', 'NORTE', 'NORDESTE', 'CENTRO-OESTE']:\n",
    "            for destiny in ['SUL', 'SUDESTE', 'NORTE', 'NORDESTE', 'CENTRO-OESTE']:\n",
    "                    if df_cleared[(df_cleared['ANO'] == year) & (df_cleared['MES'] == month) & (df_cleared['ORIGEM'] == origin) & (df_cleared['DESTINO'] == destiny)].empty:\n",
    "                        df_cleared = df_cleared.append({ 'ANO': year, 'MES': month, 'ORIGEM': origin, 'DESTINO': destiny, 'PASSAGEIROS': 0}, ignore_index=True)\n",
    "\n",
    "df_cleared.to_csv('data/data_nasc.csv', index=False)\n",
    "df_cleared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['ANO'] == 2017) & (df['MES'] == 1) & (df['ORIGEM'] == 'SUDESTE')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados estatísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['ORIGEM'])['PASSAGEIROS'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['DESTINO'])['PASSAGEIROS'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['ORIGEM', 'DESTINO'])['PASSAGEIROS'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ANO'].hist(figsize=(15,15), bins=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando Dummies\n",
    "Convertendo as colunas de texto em representação numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = data_transform.getDummies(df)\n",
    "df_dummies[df_dummies['ORIGEM_CENTRO-OESTE'] == 1].groupby(['ANO'])['PASSAGEIROS'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dummies[df_dummies['ORIGEM_SUDESTE'] == 1].groupby(['ANO'])['PASSAGEIROS'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(18 * 12 * 5 * 7)\n",
    "display(df_dummies.shape)\n",
    "\n",
    "df_inter = df_dummies[df_dummies['INTER'] == True].drop(columns=['INTER'])\n",
    "df_nasc = df_dummies[df_dummies['INTER'] == True].drop(columns=['INTER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOOS NACIONAIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando PCA nos dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dummies_nasc = df_dummies[df_dummies['INTER'] == False]\n",
    "df_pca = data_transform.aplyPCA(df_dummies_nasc.drop(columns=['PASSAGEIROS', 'INTER']))\n",
    "df_pca.plot.scatter(x='x1', y='x2', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividindo a massa de teste e realizando a normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_transform.train_test_split(df_dummies)\n",
    "data_transform.fitNormalizeData(X_train)\n",
    "X_scaled = data_transform.normalizeData(X_train)\n",
    "X_test_scaled = data_transform.normalizeData(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinar Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression = Regression()\n",
    "regression.estimate(X_scaled, X_test_scaled, y_train, y_test)\n",
    "print(\"score {}\".format(regression.best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinar Suport Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_regression = SGDRegression()\n",
    "sgd_regression.estimate(X_scaled, X_test_scaled, y_train, y_test)\n",
    "print(\"score {}\".format(sgd_regression.best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinar Linear Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_svr = LinearSVRRegression()\n",
    "linear_svr.estimate(X_scaled, X_test_scaled, y_train, y_test)\n",
    "print(\"score {}\".format(linear_svr.best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimativa Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimativa = array([[2017, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimativa_t = data_transform.normalizeData(estimativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(regression.best_clt.predict(estimativa_t))\n",
    "display(sgd_regression.best_clt.predict(estimativa_t))\n",
    "display(linear_svr.best_clt.predict(estimativa_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NN()\n",
    "nn.baseline_model()\n",
    "df_dummies_nasc = df_dummies[df_dummies['INTER'] == True]\n",
    "X = df_dummies_nasc.drop(columns=['PASSAGEIROS'])\n",
    "y = df_dummies_nasc['PASSAGEIROS']\n",
    "nn.fit(X, y, 100, 15, 2)\n",
    "nn.save_weights('pesos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "print(nn.history.history.keys())\n",
    "pl.plot(nn.history.history['loss'])\n",
    "pl.plot(nn.history.history['val_loss'])\n",
    "pl.title('model loss')\n",
    "pl.ylabel('loss')\n",
    "pl.xlabel('epoch')\n",
    "pl.legend(['train', 'test'], loc='upper left')\n",
    "pl.show()\n",
    "\n",
    "# summarize history for acc\n",
    "print(nn.history.history.keys())\n",
    "pl.plot(nn.history.history['acc'])\n",
    "pl.plot(nn.history.history['val_acc'])\n",
    "pl.title('model acc')\n",
    "pl.ylabel('acc')\n",
    "pl.xlabel('epoch')\n",
    "pl.legend(['train', 'test'], loc='upper left')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimativa = array([[2017, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]]) # 227235.0\n",
    "display(nn.predict(estimativa))\n",
    "display(nn.predict(estimativa) / 227235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimativa = array([[2017, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]]) # 5947.0\n",
    "display(nn.predict(estimativa))\n",
    "estimativa = array([[2017, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]) # 4062.0\n",
    "display(nn.predict(estimativa))\n",
    "estimativa = array([[2017, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]]) # 5386.0\n",
    "display(nn.predict(estimativa))\n",
    "estimativa = array([[2017, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]) # 5046.0\n",
    "display(nn.predict(estimativa))\n",
    "estimativa = array([[2017, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]) # 0.0\n",
    "display(nn.predict(estimativa))\n",
    "estimativa = array([[2017, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]) # 0.0\n",
    "display(nn.predict(estimativa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = NN()\n",
    "nn.baseline_model()\n",
    "nn.load_weights('pesos')\n",
    "estimativa = array([[2017, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]])\n",
    "display(nn.predict(estimativa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
