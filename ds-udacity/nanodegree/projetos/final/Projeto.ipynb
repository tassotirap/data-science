{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.4\n",
      "0.20.1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "from data_clear import DataClear\n",
    "from data_transform import DataTransform\n",
    "\n",
    "from nn import NN\n",
    "from regression import Regression\n",
    "from sgd_regression import SGDRegression\n",
    "from linear_svr_regression import LinearSVRRegression\n",
    "\n",
    "%matplotlib inline\n",
    "print(pd.__version__) # version 0.23.4\n",
    "print(sk.__version__) # version 0.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_clear = DataClear()\n",
    "data_transform = DataTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = readData('data/data_2017.csv')\n",
    "data_clear = DataClear()\n",
    "df = data_clear.readData('data/data.csv') # lendo os dados\n",
    "df = data_clear.clearNotBrazilianFlights(df) # removendo voos com origem <> de Brasil\n",
    "df = data_clear.createColumns(df) # criando novas colunas (asentos, inter e passageiros)\n",
    "df = data_clear.clearData(df) # removendo dados errados e outliers\n",
    "df = data_clear.removeNotUsedColumns(df) # removendo colunas que não serão utilizadas\n",
    "df = data_clear.renameColumsn(df) # renomeando as colunas\n",
    "df = data_clear.convertTypes(df) # convertendo os tipos\n",
    "df = data_clear.groupBy(df) # agrupando por ano, mes, origem, destino e inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados estatísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando Dummies\n",
    "Convertendo as colunas de texto em representação numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dummies = data_transform.getDummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados com Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies[(df_dummies['ANO'] == 2017) & (df_dummies['ORIGEM_NORDESTE'] == 1) & (df_dummies['DESTINO_AMÉRICA DO NORTE'] == 1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando PCA nos dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pca = data_transform.aplyPCA(df_dummies)\n",
    "df_pca.plot.scatter(x='x1', y='x2', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividindo a massa de teste e realizando a normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_transform.train_test_split(df_dummies)\n",
    "data_transform.fitNormalizeData(X_train)\n",
    "X_scaled = data_transform.normalizeData(X_train)\n",
    "X_test_scaled = data_transform.normalizeData(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinar Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = Regression()\n",
    "regression.estimate(X_scaled, X_test_scaled, y_train, y_test)\n",
    "print(\"score {}\".format(regression.best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinar Suport Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_regression = SGDRegression()\n",
    "sgd_regression.estimate(X_scaled, X_test_scaled, y_train, y_test)\n",
    "print(\"score {}\".format(sgd_regression.best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinar Linear Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svr = LinearSVRRegression()\n",
    "linear_svr.estimate(X_scaled, X_test_scaled, y_train, y_test)\n",
    "print(\"score {}\".format(linear_svr.best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimativa = array([[2017, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimativa_t = data_transform.normalizeData(estimativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(regression.best_clt.predict(estimativa_t))\n",
    "display(sgd_regression.best_clt.predict(estimativa_t))\n",
    "display(linear_svr.best_clt.predict(estimativa_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NN()\n",
    "nn.baseline_model()\n",
    "X = df_dummies.drop(columns=['PASSAGEIROS'])\n",
    "y = df_dummies['PASSAGEIROS']\n",
    "nn.fit(X, y, 1500, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(nn.predict(estimativa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
